{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc65576",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0346a",
   "metadata": {},
   "source": [
    "# Model & Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed83ce2",
   "metadata": {},
   "source": [
    "## Import model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef13af1",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = ['query: how much protein should a female eat',\n",
    "               'query: I like the blue sky',\n",
    "               \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "               \"passage: The sky is blue\",\n",
    "               \"passage: I like to eat pizza\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a05da",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959512cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "print(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "518181a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 1.1787, -0.2960, -1.1996,  ..., -0.5630, -1.3796,  1.0059],\n",
      "         [ 0.5923, -0.4263, -0.8927,  ..., -0.4820, -1.1604,  0.7519],\n",
      "         [ 0.5456, -0.6482, -1.2272,  ..., -0.7752, -1.3413,  0.6554],\n",
      "         ...,\n",
      "         [ 1.1787, -0.2960, -1.1996,  ..., -0.5630, -1.3796,  1.0059],\n",
      "         [ 1.1787, -0.2960, -1.1996,  ..., -0.5630, -1.3796,  1.0059],\n",
      "         [ 1.1787, -0.2960, -1.1996,  ..., -0.5630, -1.3796,  1.0059]],\n",
      "\n",
      "        [[ 0.6856, -0.7174, -1.6397,  ..., -0.3560, -0.4480,  0.6896],\n",
      "         [ 0.3218, -0.4208, -0.8291,  ..., -0.1230, -0.2352,  0.1965],\n",
      "         [ 0.3348, -0.3418, -1.4797,  ..., -0.2605,  0.3100, -0.1354],\n",
      "         ...,\n",
      "         [ 0.6856, -0.7174, -1.6397,  ..., -0.3560, -0.4480,  0.6896],\n",
      "         [ 0.6856, -0.7174, -1.6397,  ..., -0.3560, -0.4480,  0.6896],\n",
      "         [ 0.6856, -0.7174, -1.6397,  ..., -0.3560, -0.4480,  0.6896]],\n",
      "\n",
      "        [[ 1.4116, -0.5168, -1.6717,  ..., -0.5477, -0.7347,  1.1186],\n",
      "         [ 1.0271, -0.4023, -1.7187,  ..., -0.7665, -0.1094,  1.0865],\n",
      "         [ 1.2380, -0.6217, -1.5220,  ..., -0.8559, -0.0534,  0.4456],\n",
      "         ...,\n",
      "         [ 0.7057, -1.5266, -1.1899,  ..., -0.6165, -1.1787,  0.7268],\n",
      "         [ 1.1628, -0.5472, -1.5203,  ..., -0.7454, -0.0547,  0.5407],\n",
      "         [ 1.4116, -0.5168, -1.6717,  ..., -0.5477, -0.7347,  1.1186]],\n",
      "\n",
      "        [[ 0.9699, -0.0972, -0.9538,  ...,  0.1324,  0.1798,  0.4992],\n",
      "         [ 0.9230,  0.1620, -0.5291,  ...,  0.0888,  0.2414, -0.1655],\n",
      "         [ 0.5676, -0.4883, -0.6458,  ..., -0.2060,  0.1811, -0.2744],\n",
      "         ...,\n",
      "         [ 0.9699, -0.0972, -0.9538,  ...,  0.1324,  0.1798,  0.4992],\n",
      "         [ 0.9699, -0.0972, -0.9538,  ...,  0.1324,  0.1798,  0.4992],\n",
      "         [ 0.9699, -0.0972, -0.9538,  ...,  0.1324,  0.1798,  0.4992]],\n",
      "\n",
      "        [[ 0.8999, -0.0465, -0.8754,  ..., -0.2343, -1.7924,  0.7912],\n",
      "         [ 0.8942, -0.0747,  0.0033,  ..., -0.2201, -1.4047, -0.0580],\n",
      "         [ 0.8917, -0.3351, -0.1083,  ..., -0.5834, -1.0769, -0.0695],\n",
      "         ...,\n",
      "         [ 0.8999, -0.0465, -0.8754,  ..., -0.2343, -1.7924,  0.7912],\n",
      "         [ 0.8999, -0.0465, -0.8754,  ..., -0.2343, -1.7924,  0.7912],\n",
      "         [ 0.8999, -0.0465, -0.8754,  ..., -0.2343, -1.7924,  0.7912]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.5784,  0.3705, -0.2903,  ..., -0.1864, -0.6170, -0.1681],\n",
      "        [-0.4691,  0.3253, -0.5416,  ...,  0.2805, -0.6014,  0.0373],\n",
      "        [-0.5487,  0.4059, -0.5923,  ..., -0.1571, -0.5806, -0.2218],\n",
      "        [-0.7204,  0.3345, -0.6545,  ...,  0.3253, -0.4745,  0.1691],\n",
      "        [-0.3433,  0.4475, -0.4987,  ..., -0.2668, -0.6731, -0.0733]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**batch_dict)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeaac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize embeddings\n",
    "scores = (embeddings[:2] @ embeddings[2:].T) * 100\n",
    "print(scores.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
